{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Conv Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "import mglearn\n",
    "#import t_Mod\n",
    "from t_Mod import *\n",
    "#from t_Mod.plots_t import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    os.path.join(mglearn.datasets.DATA_PATH, \"constant(del).csv\") )\n",
    "#df2 = pd.read_csv(\n",
    "#    os.path.join(mglearn.datasets.DATA_PATH, \"constant(val).csv\") )\n",
    "# 예제를 위해 몇개의 열만 선택합니다\n",
    "#df = df[['IR', 'FlowHt', 'Const', 'Var', 'Base', 'MixS75','MixS50','MixS25']]\n",
    "#df = df[['IR', 'FlowHt', 'Sand','Ash','delIR','delFlow']]\n",
    "df = df[['IR', 'FlowHt', 'Sand','Ash','delIR','delFlow']]\n",
    "#df2 = df2[['IR', 'FlowHt', 'Sand','Ash']]\n",
    "df['delIF'] = df['delFlow']/df['delIR']*-1\n",
    "\n",
    "df['delIF']=df['delIF'].replace(np.nan, 0)\n",
    "df = df[['IR', 'FlowHt', 'Sand','Ash' ]]\n",
    "\n",
    "display(df.head())\n",
    "#display(df2.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()\n",
    "print(df[58:116])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(df.iloc[0:58,0], df.iloc[0:58,1], 'g-'\n",
    "         , df.iloc[58:116,0], df.iloc[58:116,1],'r--'\n",
    "         ,df.iloc[116:174,0], df.iloc[116:174,1],'b-'\n",
    "         ,df.iloc[174:232,0], df.iloc[174:232,1], 'm-')\n",
    "plt.xlabel('norm IR')\n",
    "plt.ylabel('Flow Height [m]')\n",
    "#plt.axis('equal')\n",
    "#plt.axis('square')\n",
    "plt.xlim([plt.xlim()[1], 0])\n",
    "#plt.ylim([0,plt.ylim()[1]])\n",
    "#_ = plt.plot([-100, 100], [-100, 100])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ## 데이터 정규화\n",
    "\n",
    "num_features = df.shape[1]\n",
    "num_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df['FlowHt']=(df['FlowHt']-df['FlowHt'].mean())/df['FlowHt'].std()\n",
    "\n",
    "\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_mean = df.mean()\n",
    "df_std = df.std()\n",
    "df_std_s = (df - df_mean) / df_std\n",
    "df_std_m = df_std_s.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std_m)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=90)\n",
    "df_std_s.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data\n",
    "df_org = df\n",
    "#df = df_std_s\n",
    "\n",
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)*0.5\n",
    "\n",
    "curve_0 = df[0:int(n*0.25)].copy()\n",
    "curve_1 = df[int(n*0.25):int(n*0.5)].copy()\n",
    "curve_2 = df[int(n*0.5):int(n*0.75)].copy()\n",
    "curve_3 = df[int(n*0.75):int(n)].copy()\n",
    "curve_4 = df[int(n):].copy()\n",
    "#train_df_s = train_df_s.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()\n",
    "#print(df[58:116])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(df.iloc[0:58,0], df.iloc[0:58,1], 'g-'\n",
    "         , df.iloc[58:116,0], df.iloc[58:116,1],'r--'\n",
    "         ,df.iloc[116:174,0], df.iloc[116:174,1],'b-'\n",
    "         ,df.iloc[174:232,0], df.iloc[174:232,1], 'm-')\n",
    "plt.xlabel('norm IR')\n",
    "plt.ylabel('Flow Height [m]')\n",
    "#plt.axis('equal')\n",
    "#plt.axis('square')\n",
    "#plt.xlim([plt.xlim()[1], -2.5])\n",
    "#plt.ylim([0,plt.ylim()[1]])\n",
    "#_ = plt.plot([-100, 100], [-100, 100])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### curve_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crv_0 = curve_0.copy()\n",
    "crv_0 = crv_0.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#m1 = int(n*0.2)\n",
    "m1 = int(len(curve_0))\n",
    "for i in range(1, 4):\n",
    "    m = m1*0.33334*i\n",
    "    train_df_0 = crv_0[0:int(m*0.8)]\n",
    "    val_df_0 = crv_0[int(m*0.8):int(m)]\n",
    "#    test_df_0 = crv_0[int(m*0.8):int(m)]\n",
    "#    test_df_0 = crv_0[int(n*0.25*0.2*i-3):int(n*0.25*0.2*(i+1))]\n",
    "    exec(f'train_df_0{i-1} = train_df_0')\n",
    "    exec(f'val_df_0{i-1} = val_df_0')\n",
    "#    exec(f'test_df_0{i-1} = test_df_0')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train_total = {0: train_df_00 , 1: train_df_01, 2: train_df_02, 3: train_df_03}\n",
    "#val_total = {0: val_df_00 , 1: val_df_01, 2: val_df_02, 3: val_df_03}\n",
    "#test_total = {0: test_df_00 , 1: test_df_01, 2: test_df_02, 3: test_df_03}\n",
    "\n",
    "train_total = [train_df_00, train_df_01, train_df_02]\n",
    "val_total = [val_df_00, val_df_01, val_df_02]\n",
    "#test_total = [test_df_00, test_df_01, test_df_02]\n",
    "\n",
    "#ttt = { 'tr' : train_total, 'va' : val_total, 'te' : test_total}\n",
    "ttt = { 'tr' : train_total, 'va' : val_total, 'te' : val_total}\n",
    "ttt = pd.DataFrame(ttt)\n",
    "print(ttt.columns)\n",
    "print(ttt.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from t_Mod.plots_t import plot_curve, eval, add_curve # absolute path, import 함수\n",
    "\n",
    "for i in range(0, 3) :\n",
    " #   for x in dat_list :\n",
    "        plt.figure(figsize=(5, 2))\n",
    "        tr = ttt.iloc[i]['tr']\n",
    "        va = ttt.iloc[i]['va']\n",
    "        te = ttt.iloc[i]['te']\n",
    "#        plot_curve(tr, va, te)\n",
    "        plots_t.plot_curve(tr, va, te)\n",
    "#        t_Mod.plots_t.plot_curve(tr, va, te)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### curve_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crv_1 = curve_1.copy()\n",
    "#crv_1 = crv_1.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m1 = int(len(curve_1))\n",
    "for i in range(1, 4):\n",
    "    m = m1*0.33334*i\n",
    "    train_df_1 = crv_1[0:int(m*0.8)]\n",
    "    val_df_1 = crv_1[int(m*0.8):int(m)]\n",
    "    exec(f'train_df_1{i-1} = train_df_1')\n",
    "    exec(f'val_df_1{i-1} = val_df_1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_t_1 = {0: train_df_10 , 1: train_df_11, 2: train_df_12 }\n",
    "val_t_1 = {0: val_df_10 , 1: val_df_11, 2: val_df_12 }\n",
    "#test_t_1 = {0: test_df_10 , 1: test_df_11, 2: test_df_12 }\n",
    "\n",
    "ttt_1 = { 'tr' : train_t_1, 'va' : val_t_1, 'te' : val_t_1}\n",
    "ttt_1 = pd.DataFrame(ttt_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(0, 3) :\n",
    " #   for x in dat_list :\n",
    "        plt.figure(figsize=(5, 2))\n",
    "        tr = ttt_1.iloc[i]['tr']\n",
    "        va = ttt_1.iloc[i]['va']\n",
    "        te = ttt_1.iloc[i]['te']\n",
    "        plots_t.plot_curve(tr, va, te)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### curve_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crv_2 = curve_2.copy()\n",
    "#crv_2 = crv_2.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m1 = int(len(curve_2))\n",
    "for i in range(1, 4):\n",
    "    m = m1*0.33334*i\n",
    "    train_df_2 = crv_2[0:int(m*0.8)]\n",
    "    val_df_2 = crv_2[int(m*0.8):int(m)]\n",
    "    exec(f'train_df_2{i-1} = train_df_2')\n",
    "    exec(f'val_df_2{i-1} = val_df_2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_t_2 = {0: train_df_20 , 1: train_df_21, 2: train_df_22 }\n",
    "val_t_2 = {0: val_df_20 , 1: val_df_21, 2: val_df_22 }\n",
    "#test_t_1 = {0: test_df_10 , 1: test_df_11, 2: test_df_12 }\n",
    "\n",
    "ttt_2 = { 'tr' : train_t_2, 'va' : val_t_2, 'te' : val_t_2}\n",
    "ttt_2 = pd.DataFrame(ttt_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(0, 3) :\n",
    " #   for x in dat_list :\n",
    "        plt.figure(figsize=(5, 2))\n",
    "        tr = ttt_2.iloc[i]['tr']\n",
    "        va = ttt_2.iloc[i]['va']\n",
    "        te = ttt_2.iloc[i]['te']\n",
    "        plots_t.plot_curve(tr, va, te)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### curve_3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crv_3 = curve_3.copy()\n",
    "#crv_2 = crv_2.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m1 = int(len(curve_3))\n",
    "for i in range(1, 4):\n",
    "    m = m1*0.33334*i\n",
    "    train_df_3 = crv_3[0:int(m*0.8)]\n",
    "    val_df_3 = crv_3[int(m*0.8):int(m)]\n",
    "    exec(f'train_df_3{i-1} = train_df_3')\n",
    "    exec(f'val_df_3{i-1} = val_df_3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_t_3 = {0: train_df_30 , 1: train_df_31, 2: train_df_32 }\n",
    "val_t_3 = {0: val_df_30 , 1: val_df_31, 2: val_df_32 }\n",
    "#test_t_1 = {0: test_df_10 , 1: test_df_11, 2: test_df_12 }\n",
    "\n",
    "ttt_3 = { 'tr' : train_t_3, 'va' : val_t_3, 'te' : val_t_3}\n",
    "ttt_3 = pd.DataFrame(ttt_3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(0, 3) :\n",
    " #   for x in dat_list :\n",
    "        plt.figure(figsize=(5, 2))\n",
    "        tr = ttt_3.iloc[i]['tr']\n",
    "        va = ttt_3.iloc[i]['va']\n",
    "        te = ttt_3.iloc[i]['te']\n",
    "        plots_t.plot_curve(tr, va, te)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### WindowGrerator Class\n",
    "#### WinGen()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# WindowGen needs train_df\n",
    "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "train_df = train_df_01.copy()\n",
    "val_df = val_df_01.copy()\n",
    "test_df = val_df_01.copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "single_step_window = Class_t.WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "single_step_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "single_step_window_t = Class_t.WinGen(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "single_step_window_t\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CONV_WIDTH = 3\n",
    "conv_window = Class_t.WindowGenerator(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "        train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "\n",
    "conv_window\n",
    "\n",
    "conv_window_t = Class_t.WinGen(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "        train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "\n",
    "conv_window_t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wide_window = Class_t.WindowGenerator(\n",
    "    input_width=8, label_width=8, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "\n",
    "wide_window\n",
    "#print(wide_window)\n",
    "wide_window_t = Class_t.WinGen(\n",
    "    input_width=8, label_width=8, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "\n",
    "wide_window_t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABEL_WIDTH = 8\n",
    "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
    "wide_conv_window = Class_t.WindowGenerator(\n",
    "    input_width=INPUT_WIDTH,\n",
    "    label_width=LABEL_WIDTH,\n",
    "    shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "\n",
    "wide_conv_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wide_conv_window_t = Class_t.WinGen(\n",
    "    input_width=INPUT_WIDTH,\n",
    "    label_width=LABEL_WIDTH,\n",
    "    shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "\n",
    "wide_conv_window_t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convolution Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32,\n",
    "                           kernel_size=(CONV_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "_ = compile.compile_2(conv_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_loss_con = []\n",
    "va_loss_con= []\n",
    "tr_mae_con = []\n",
    "va_mae_con = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loss_con, val_loss_con, train_mae_con, val_mae_con =  \\\n",
    "    plots_t.add_curve(curve=ttt, window=conv_window,\n",
    "            window_t=conv_window_t, model=conv_model, npat= 5,\n",
    "                      num_epoch=100, add_num=0, df_name='temp')\n",
    "        #     window_t=conv_window_t, model=conv_model, npat= 10, num_epoch=100 )\n",
    "tr_loss_con = tr_loss_con + train_loss_con\n",
    "va_loss_con = va_loss_con + val_loss_con\n",
    "tr_mae_con = tr_mae_con + train_mae_con\n",
    "va_mae_con = va_mae_con + val_mae_con\n",
    "\n",
    "print(f'End of curve0 -----------------')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#conv_window_t.plot_batch(conv_model, dset_name='train', n_batch=10, figures=0)\n",
    "#conv_window_t.plot_batch(conv_model, 'train', n_batch=1, figures='True', xy_fig='True')\n",
    "#conv_window_t.plot_batch(conv_model, 'val', n_batch=10,   xy_fig='True')\n",
    "#conv_window_t.plot_batch(conv_model, 'train', n_batch=2 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#conv_window_t.plot_xy(conv_model,  n_batch=10 )\n",
    "#plt.gca().set_title('Curve 0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ++++++++++++++++++++++++++++++++++++++++++\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loss_con, val_loss_con, train_mae_con, val_mae_con =  \\\n",
    "    plots_t.add_curve(curve=ttt_1, window=conv_window,\n",
    "          window_t=conv_window_t, model=conv_model, npat= 10, num_epoch=100, add_num=0, df_name='curve')\n",
    "tr_loss_con = tr_loss_con + train_loss_con\n",
    "va_loss_con = va_loss_con + val_loss_con\n",
    "tr_mae_con = tr_mae_con + train_mae_con\n",
    "va_mae_con = va_mae_con + val_mae_con\n",
    "\n",
    "print(f'End of curve1 -----------------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_window_t.train_df = train_df_02\n",
    "dataset = conv_window.train\n",
    "n = 1\n",
    "for batch in dataset :\n",
    "  inputs, targets = batch\n",
    "  print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {targets.shape}')\n",
    "  #plot_3(inputs, targets, 8, n)\n",
    "  n += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_window_t.train_df = train_df_12\n",
    "\n",
    "conv_window_t.plot_xy(conv_model,  n_batch=10 )\n",
    "plt.gca().set_title('Curve 1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ++++++++++++++++++++++++++++++++++++++++++\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "train_loss_con, val_loss_con, train_mae_con, val_mae_con =  \\\n",
    "    plots_t.add_curve(curve=ttt_2, window=conv_window,\n",
    "        window_t=conv_window_t, model=conv_model, npat= 10, num_epoch=200, add_num=0, df_name='temp')\n",
    "tr_loss_con = tr_loss_con + train_loss_con\n",
    "va_loss_con = va_loss_con + val_loss_con\n",
    "tr_mae_con = tr_mae_con + train_mae_con\n",
    "va_mae_con = va_mae_con + val_mae_con\n",
    "\n",
    "print(f'End of curve2 -----------------')\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "#conv_window_t.train_df = ttt_2.iloc[3]['tr']\n",
    "conv_window_t.plot_xy(conv_model,  n_batch=10 )\n",
    "plt.gca().set_title('Curve 2')\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ++++++++++++++++++++++++++++++++++++++++++\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loss_con, val_loss_con, train_mae_con, val_mae_con =  \\\n",
    "    plots_t.add_curve(curve=ttt_3, window=conv_window,\n",
    "                                window_t=conv_window_t, model=conv_model, npat= 20,\n",
    "                      num_epoch=100, add_num=0 , df_name='temp')\n",
    "tr_loss_con = tr_loss_con + train_loss_con\n",
    "va_loss_con = va_loss_con + val_loss_con\n",
    "tr_mae_con = tr_mae_con + train_mae_con\n",
    "va_mae_con = va_mae_con + val_mae_con\n",
    "\n",
    "print(f'End of curve3 -----------------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_window_t.plot_xy(conv_model,  n_batch=10 )\n",
    "plt.gca().set_title('Curve 3')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ++++++++++++++++++++++++++++++++++++++++++\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set curve3 to the test data set\n",
    "conv_window_t.train_df = train_df_32\n",
    "conv_window_t.val_df = train_df_32\n",
    "conv_window_t.test_df = train_df_32\n",
    "\n",
    "conv_window_t.plot_xy(conv_model,  n_batch=10, dset_name='train' )\n",
    "plt.gca().set_title('Test Curve')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_loss_con_avg = np.mean(train_loss_con)\n",
    "va_loss_con_avg = np.mean(val_loss_con)\n",
    "tr_mae_con_avg = np.mean(train_mae_con)\n",
    "va_mae_con_avg = np.mean(val_mae_con)\n",
    "\n",
    "#val_performance['linear'] = lstm_model.evaluate(single_step_window.val)\n",
    "#performance['linear'] = lstm_model.evaluate(single_step_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_perform = {}\n",
    "va_perform = {}\n",
    "te_perform = {}\n",
    "\n",
    "tr_perform['conve']= [tr_loss_con_avg, tr_mae_con_avg]\n",
    "va_perform['conve']= [va_loss_con_avg, va_mae_con_avg]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr0 = ttt.iloc[2]['tr']\n",
    "tr1 = tr0.append(ttt_1.iloc[2]['tr'])\n",
    "tr2 = tr1.append(ttt_2.iloc[2]['tr'])\n",
    "tr3 = tr2.append(ttt_3.iloc[2]['tr'])\n",
    "\n",
    "va0 = ttt.iloc[2]['va']\n",
    "va1 = va0.append(ttt_1.iloc[2]['va'])\n",
    "va2 = va1.append(ttt_2.iloc[2]['va'])\n",
    "va3 = va2.append(ttt_3.iloc[2]['va'])\n",
    "\n",
    "te0 = ttt.iloc[2]['te']\n",
    "te1 = te0.append(ttt_1.iloc[2]['te'])\n",
    "te2 = te1.append(ttt_2.iloc[2]['te'])\n",
    "te3 = te2.append(ttt_3.iloc[2]['te'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    conv_window_t.train_df = tr3\n",
    "    conv_window_t.val_df = va3\n",
    "    conv_window_t.test_df = te3\n",
    "\n",
    "    conv_window_t.plot_xy(conv_model,  n_batch=20 )\n",
    "    plt.gca().set_title('All Curves')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% all curves\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize = (12,7))\n",
    "\n",
    "# curve 4\n",
    "crv_4 = curve_4.copy()\n",
    "m = len(crv_4)\n",
    "#train_df_4 = crv_4[0:int(m)]  #all\n",
    "\n",
    "train_df_4 = crv_4[0:int(m*0.25)]  #40% 60%\n",
    "plots_t.plot_all(train_df_4,  model=conv_model, window_t=conv_window_t, set_name='S40 A60', marker2='x', edgecolor2='r')\n",
    "\n",
    "train_df_4 = crv_4[int(m*0.25):int(m*0.5)]   #60% 40%\n",
    "plots_t.plot_all(train_df_4,  model=conv_model, window_t=conv_window_t,set_name='S60 A40')\n",
    "\n",
    "train_df_4 = crv_4[int(m*0.5):int(m*0.75)]  #10% 90%\n",
    "plots_t.plot_all(train_df_4,  model=conv_model, window_t=conv_window_t,set_name='S10 A90')\n",
    "\n",
    "train_df_4 = crv_4[ int(m*0.75):int(m*1.00)]  #90% 10%\n",
    "plots_t.plot_all(train_df_4,  model=conv_model, window_t=conv_window_t,set_name='S90 A10')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "train_df_3 = curve_3.copy()\n",
    "plots_t.plot_all(train_df_3, set_name='3 s25a75',   model=conv_model,window_t=conv_window_t,marker2='o' , edgecolor2 ='b')\n",
    "\n",
    "#------------------------------------------\n",
    "train_df_2 = curve_2.copy()\n",
    "plots_t.plot_all(train_df_2, set_name='2 s50a50',   model=conv_model,window_t=conv_window_t,marker2='o' , edgecolor2 ='g')\n",
    "#------------------------------------------\n",
    "train_df_1 = curve_1.copy()\n",
    "plots_t.plot_all(train_df_1, set_name='1 s75a25',  model=conv_model,window_t=conv_window_t, marker2='o' , edgecolor2 ='g')\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "train_df_0 = curve_0.copy()\n",
    "plots_t.plot_all(train_df_0, set_name='0', marker2='o' ,model=conv_model,window_t=conv_window_t, edgecolor2 ='g')\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------\n",
    "ax2.set_xlabel('norm IR')\n",
    "ax2.set_ylabel('Flow Height [m]')\n",
    "        #ax2.set_xlim([plt.xlim()[1], -2.5])\n",
    "ax2.set_xlim([1., 0])\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "         curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-'\n",
    "          ,curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-')\n",
    "#------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABEL_WIDTH = 8\n",
    "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
    "wide_conv_window = Class_t.WindowGenerator(\n",
    "    input_width=INPUT_WIDTH,\n",
    "    label_width=LABEL_WIDTH,\n",
    "    shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "\n",
    "wide_conv_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wide_conv_window_t = Class_t.WinGen(\n",
    "    input_width=INPUT_WIDTH,\n",
    "    label_width=LABEL_WIDTH,\n",
    "    shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['FlowHt'])\n",
    "\n",
    "wide_conv_window_t\n",
    "\n",
    "print(\"Wide conv window\")\n",
    "print('Input shape:', wide_conv_window.example[0].shape)\n",
    "print('Labels shape:', wide_conv_window.example[1].shape)\n",
    "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n=1\n",
    "for example_inputs, example_labels in wide_conv_window.train.take(200): #1534, 6\n",
    "#for example_inputs, example_labels in single_step_window.train.take(3):\n",
    "#for example_inputs, example_labels in wide_window.train.take(2000): #1533 15\n",
    "  print(n)\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "  n += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 더 넓은 창에 모델의 예측값을 플롯할 수 있습니다. 첫 번째 예측 전 3개의 입력 타임스텝에 주목하세요. 여기서 모든 예측은 이전 3개의 타임스텝에 기초합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wide_conv_window.plot(conv_model)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    wide_conv_window_t.train_df = tr3\n",
    "    wide_conv_window_t.val_df = va3\n",
    "    wide_conv_window_t.test_df = te3\n",
    "    wide_conv_window_t.plot_batch(conv_model,n_batch = 1, figures='True')\n",
    "\n",
    "#(self, model=None, dset_name=None, plot_col='FlowHt', max_subplots=40, n_batch=None,\n",
    "#               figures=None, xy_fig=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    wide_conv_window_t.train_df = ttt.iloc[2]['tr']\n",
    "    wide_conv_window_t.val_df = ttt.iloc[2]['va']\n",
    "    wide_conv_window_t.test_df = ttt.iloc[2]['te']\n",
    "\n",
    "    wide_conv_window_t.plot_xy(conv_model,  n_batch=20 )\n",
    "    plt.gca().set_title('Curve 0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    wide_conv_window_t.train_df = ttt_1.iloc[2]['tr']\n",
    "    wide_conv_window_t.val_df = ttt_1.iloc[2]['va']\n",
    "    wide_conv_window_t.test_df = ttt_1.iloc[2]['te']\n",
    "\n",
    "    wide_conv_window_t.plot_xy(conv_model,  n_batch=20 )\n",
    "    plt.gca().set_title('Curve 0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    wide_conv_window_t.train_df = ttt_2.iloc[2]['tr']\n",
    "    wide_conv_window_t.val_df = ttt_2.iloc[2]['va']\n",
    "    wide_conv_window_t.test_df = ttt_2.iloc[2]['te']\n",
    "\n",
    "    wide_conv_window_t.plot_xy(conv_model,  n_batch=20 )\n",
    "    plt.gca().set_title('Curve 0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    wide_conv_window_t.train_df = ttt_3.iloc[2]['tr']\n",
    "    wide_conv_window_t.val_df = ttt_3.iloc[2]['va']\n",
    "    wide_conv_window_t.test_df = ttt_3.iloc[2]['te']\n",
    "\n",
    "    wide_conv_window_t.plot_xy(conv_model,  n_batch=20 )\n",
    "    plt.gca().set_title('Curve 0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    wide_conv_window_t.train_df = tr3\n",
    "    wide_conv_window_t.val_df = va3\n",
    "    wide_conv_window_t.test_df = te3\n",
    "\n",
    "    wide_conv_window_t.plot_xy(conv_model,  n_batch=20 )\n",
    "    plt.gca().set_title('Curve 0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wide_conv_window_t.plot_batch(conv_model, dset_name='test', n_batch =0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wide_conv_window_t.plot_batch(conv_model, dset_name='val', n_batch =0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# curve 4\n",
    "crv_4 = curve_4.copy()\n",
    "\n",
    "m = len(crv_4)\n",
    "\n",
    "#train_df_4 = crv_4[0:int(m*0.5)]\n",
    "#train_df_4 = crv_4[0:int(m*0.25)]\n",
    "#val_df_4 = crv_4[0:int(m*0.25)]\n",
    "\n",
    "#train_df_4 = crv_4[ :int(m*1.00)]\n",
    "train_df_4 = crv_4[ :int(m*1.00)]\n",
    "\n",
    "#train_df_4 = crv_4[int(m*0.25):int(m*0.5)]\n",
    "val_df_4 = train_df_4\n",
    "\n",
    "wide_conv_window_t.train_df = train_df_4\n",
    "wide_conv_window_t.val_df = val_df_4\n",
    "wide_conv_window_t.test_df = val_df_4\n",
    "\n",
    "#wide_conv_window_t.plot_xy(conv_model,  n_batch=20 )\n",
    "#plt.gca().set_title('Curve4')\n",
    "\n",
    "\n",
    "dataset = wide_conv_window_t.train\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "\n",
    "for i, batch in enumerate(dataset) :\n",
    "  inputs, targets, lab = batch\n",
    "  predictions = conv_model(inputs)\n",
    "#  print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "#  print(f'Labels shape (batch, time, features): {targets.shape}')\n",
    " # ax2.scatter(lab[:,:,0], targets[:,:,0])\n",
    "#  ax2.scatter(lab[:,:,0], predictions[:,:,0], marker='o', facecolors='none'\n",
    "  ax2.scatter(lab[:,:,0], predictions[:,:,0], marker='o'\n",
    "              , edgecolor ='b')\n",
    "\n",
    "\n",
    "ax2.set_xlabel('norm IR')\n",
    "ax2.set_ylabel('Flow Height [m]')\n",
    "#ax2.set_xlim([plt.xlim()[1], -2.5])\n",
    "#ax2.set_xlim([1.2, -2.5])\n",
    "\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "        curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-',)\n",
    "#         curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-')\n",
    "\n",
    "wide_conv_window_t.train_df = ttt_3.iloc[2]['tr']\n",
    "    #.append(ttt_3.iloc[2]['va'])\n",
    "                        #    .append(ttt_3.iloc[2]['te'])\n",
    "ax2.invert_xaxis()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fit any input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\n",
    "    os.path.join(mglearn.datasets.DATA_PATH, \"anycurve2.csv\") )\n",
    "#df2 = pd.read_csv(\n",
    "#    os.path.join(mglearn.datasets.DATA_PATH, \"constant(val).csv\") )\n",
    "# 예제를 위해 몇개의 열만 선택합니다\n",
    "#df = df[['IR', 'FlowHt', 'Const', 'Var', 'Base', 'MixS75','MixS50','MixS25']]\n",
    "#df = df[['IR', 'FlowHt', 'Sand','Ash','delIR','delFlow']]\n",
    "df3 = df3[['IR', 'FlowHt', 'Sand','Ash','delIR','delFlow']]\n",
    "#df2 = df2[['IR', 'FlowHt', 'Sand','Ash']]\n",
    "df3['delIF'] = df3['delFlow']/df3['delIR']*-1\n",
    "\n",
    "df3['delIF']=df3['delIF'].replace(np.nan, 0)\n",
    "df3 = df3[['IR', 'FlowHt', 'Sand','Ash' ]]\n",
    "\n",
    "display(df3.head())\n",
    "#display(df2.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df3_mean = df3.mean()\n",
    "df3_std = df3.std()\n",
    "df3_std_s = (df3 - df3_mean) / df3_std\n",
    "df3_std_m = df3_std_s.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df3_std_m)\n",
    "_ = ax.set_xticklabels(df3.keys(), rotation=90)\n",
    "df3_std_s.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df3_org = df3\n",
    "#df3 = df3_std_s\n",
    "\n",
    "#a =ttt_1.iloc[2]['tr']\n",
    "#b=a.append(ttt_1.iloc[2]['va'])\n",
    "#c = b.append(ttt_1.iloc[2]['te'])\n",
    "n = len(df3)\n",
    "c_0 = df3[0:int(n*0.25)].copy()\n",
    "c_1 = df3[int(n*0.25):int(n*0.5)].copy()\n",
    "c_2 = df3[int(n*0.5):int(n*0.75)].copy()\n",
    "c_3 = df3[int(n*0.75):int(n)].copy()\n",
    "\n",
    "\n",
    "wide_conv_window_t.train_df = c_0\n",
    "\n",
    "dataset = wide_conv_window_t.train\n",
    "fig, ax2 = plt.subplots()\n",
    "\n",
    "for i, batch in enumerate(dataset) :\n",
    "  inputs, targets, lab = batch\n",
    "  predictions = conv_model(inputs)\n",
    "  ax2.scatter(lab[:,:,0], predictions[:,:,0], marker='o', edgecolor ='b')\n",
    "#ax2.set_xlim([1.2, -2.5])\n",
    "\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "        curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-',\n",
    "        curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-',)\n",
    "\n",
    "ax2.plot(c_1.iloc[0:58,0], c_1.iloc[0:58,1], 'g--',\n",
    "        c_2.iloc[0:58,0], c_2.iloc[0:58,1], 'r--',\n",
    "        c_3.iloc[0:58,0], c_3.iloc[0:58,1], 'b--',\n",
    "        c_0.iloc[0:58,0], c_0.iloc[0:58,1], 'm--',)\n",
    "\n",
    "\n",
    "ax2.invert_xaxis()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize = (12,7))\n",
    "\n",
    "#------------------------------------------\n",
    "train_df_3 = curve_3.copy()\n",
    "#plots_t.plot_all(train_df_3, set_name='3 s25a75',   model=conv_model,window_t=conv_window_t,marker2='o' , edgecolor2 ='b')\n",
    "\n",
    "#------------------------------------------\n",
    "train_df_2 = curve_2.copy()\n",
    "#plots_t.plot_all(train_df_2, set_name='2 s50a50',   model=conv_model,window_t=conv_window_t,marker2='o' , edgecolor2 ='g')\n",
    "#------------------------------------------\n",
    "train_df_1 = curve_1.copy()\n",
    "#plots_t.plot_all(train_df_1, set_name='1 s75a25',  model=conv_model,window_t=conv_window_t, marker2='o' , edgecolor2 ='g')\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "train_df_0 = curve_0.copy()\n",
    "#plots_t.plot_all(train_df_0, set_name='0', marker2='o' ,model=conv_model,window_t=conv_window_t, edgecolor2 ='g')\n",
    "\n",
    "\n",
    "#------------------------------------------\n",
    "ax2.set_xlabel('norm IR')\n",
    "ax2.set_ylabel('Flow Height [m]')\n",
    "        #ax2.set_xlim([plt.xlim()[1], -2.5])\n",
    "#ax2.set_xlim([1., 0])\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "         curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-'\n",
    "          ,curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-')\n",
    "#------------------------------------------\n",
    "ax2.plot(c_1.iloc[0:58,0], c_1.iloc[0:58,1], 'g--',\n",
    "        c_2.iloc[0:58,0], c_2.iloc[0:58,1], 'r--',\n",
    "        c_3.iloc[0:58,0], c_3.iloc[0:58,1], 'b--',\n",
    "        c_0.iloc[0:58,0], c_0.iloc[0:58,1], 'm--',)\n",
    "\n",
    "\n",
    "def split_window( features ):\n",
    "    inputs = features[:, input_slice, :]\n",
    "    labels = features[:, labels_slice, :]\n",
    "    lab = features[:,  labels_slice, 0:2]\n",
    "\n",
    "    labels = tf.stack( [labels[:, :, 1] ])\n",
    "    print(f'in split_window : {inputs}')\n",
    "    print(f'in split_window : {labels}')\n",
    "\n",
    "    return inputs, labels, lab\n",
    "def makedata(data) :\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False, #default\n",
    "#      shuffle=True,\n",
    "      batch_size=60,)\n",
    "    ds = ds.map(split_window )\n",
    "    return ds\n",
    "\n",
    "input_width = 3\n",
    "label_width = 1\n",
    "shift = 1\n",
    "total_window_size = input_width + shift\n",
    "input_slice = slice(0, input_width)\n",
    "#input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "label_start = total_window_size - label_width\n",
    "labels_slice = slice(label_start, None)\n",
    "#label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "train_df_40 = c_0\n",
    "train_df_41 = c_1\n",
    "train_df_42 = c_2\n",
    "train_df_43 = c_3\n",
    "\n",
    "\n",
    "#data_set = [train_df_40, train_df_41, train_df_42, train_df_43  ]\n",
    "#data_set = [train_df_41, train_df_42, train_df_43  ]\n",
    "data_set = [train_df_43]\n",
    "\n",
    "for data in data_set :\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
    "\n",
    "    conv_window_t.train_df = data\n",
    "    ds = conv_window_t.train\n",
    "\n",
    "#    ds = makedata(data)\n",
    "\n",
    "    for i, batch in enumerate(ds) :\n",
    "        inputs, labels, lab = batch\n",
    "        inputs = inputs.numpy()\n",
    "        if i>0 :\n",
    "            inputs[0, 0:3, 1] = inputs_res[-1:, -3: , 1]\n",
    "            inputs[1, 0:2, 1] = inputs_res[-1:, -2: , 1]\n",
    "            inputs[2, 0:1, 1] = inputs_res[-1:, -1: , 1]\n",
    "\n",
    "        for n in range (len(inputs)) :\n",
    "                predictions = conv_model(inputs[n:n+1])\n",
    "                predictions = predictions.numpy()\n",
    "                if n > 0 :\n",
    "                    predictions0 = conv_model(inputs[n-1:n])\n",
    "                    predictions0 = predictions0.numpy()\n",
    "\n",
    "                    if predictions0[0,0,0] >  predictions[0,0,0] :\n",
    "                        predictions[0,0,0] = inputs[n+1,2,1]\n",
    "                        predictions[0,0,0] = inputs[n,-1:,1]\n",
    "                inputs[n+1,2,1] =predictions[0,0,0]\n",
    "\n",
    "                if n < len(inputs)-2 :\n",
    "                    inputs[n+2,1,1] =predictions[0,0,0]\n",
    "                else : break\n",
    "                if n < len(inputs)-3 :\n",
    "                    inputs[n+3,0,1] =predictions[0,0,0]\n",
    "                else :\n",
    "                    continue\n",
    "\n",
    "\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        inputs_res = inputs\n",
    "\n",
    "        predictions = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        predictions = conv_model(inputs)\n",
    "        ax2.scatter(lab[:,:, 0],  predictions[:, :, 0],marker='o', edgecolors=None, label='Predictions'\n",
    "             ,facecolors='red'  )# , c='#ff7f0e', s=64)\n",
    "        #ax2.scatter(inputs[:, :, 0], inputs[:, :, 1],label='Inputs', marker='x')\n",
    "\n",
    "\n",
    "ax2.invert_xaxis()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize = (12,7))\n",
    "\n",
    "#------------------------------------------\n",
    "ax2.set_xlabel('norm IR')\n",
    "ax2.set_ylabel('Flow Height [m]')\n",
    "\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "         curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-'\n",
    "          ,curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-')\n",
    "#------------------------------------------\n",
    "ax2.plot(c_1.iloc[0:58,0], c_1.iloc[0:58,1], 'g--',\n",
    "        c_2.iloc[0:58,0], c_2.iloc[0:58,1], 'r--',\n",
    "        c_3.iloc[0:58,0], c_3.iloc[0:58,1], 'b--',\n",
    "        c_0.iloc[0:58,0], c_0.iloc[0:58,1], 'm--',)\n",
    "\n",
    "\n",
    "def split_window( features ):\n",
    "    inputs = features[:, input_slice, :]\n",
    "    labels = features[:, labels_slice, :]\n",
    "    lab = features[:,  labels_slice, 0:2]\n",
    "\n",
    "    labels = tf.stack( [labels[:, :, 1] ])\n",
    "    print(f'in split_window : {inputs}')\n",
    "    print(f'in split_window : {labels}')\n",
    "\n",
    "    return inputs, labels, lab\n",
    "def makedata(data) :\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False, #default\n",
    "#      shuffle=True,\n",
    "      batch_size=16,)\n",
    "    ds = ds.map(split_window )\n",
    "    return ds\n",
    "\n",
    "input_width = 3\n",
    "label_width = 1\n",
    "shift = 1\n",
    "total_window_size = input_width + shift\n",
    "input_slice = slice(0, input_width)\n",
    "#input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "label_start = total_window_size - label_width\n",
    "labels_slice = slice(label_start, None)\n",
    "#label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "train_df_40 = c_0\n",
    "train_df_41 = c_1\n",
    "train_df_42 = c_2\n",
    "train_df_43 = c_3\n",
    "\n",
    "\n",
    "#data_set = [train_df_40, train_df_41, train_df_42, train_df_43  ]\n",
    "#data_set = [train_df_41, train_df_42, train_df_43  ]\n",
    "data_set = [train_df_43]\n",
    "\n",
    "for data in data_set :\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
    "\n",
    "#    conv_window_t.train_df = data\n",
    "#    ds = conv_window_t.train\n",
    "\n",
    "    ds = makedata(data)\n",
    "\n",
    "    for i, batch in enumerate(ds) :\n",
    " #       if i > 3 : break\n",
    "        inputs, labels, lab = batch\n",
    "        inputs = inputs.numpy()\n",
    "        if i>0 :\n",
    "        #    inputs[0, 0:3, 1] = inputs_res[-1:, -3: , 1]\n",
    "        #    inputs[1, 0:2, 1] = inputs_res[-1:, -2: , 1]\n",
    "        #    inputs[2, 0:1, 1] = inputs_res[-1:, -1: , 1]\n",
    "            for j in range (0, CONV_WIDTH-1) :\n",
    "                inputs[j, 0:CONV_WIDTH-j, 1] = inputs_res[-1:, j-CONV_WIDTH: , 1]\n",
    "\n",
    "        #ax2.scatter(inputs[:, :, 0], inputs[:, :, 1],label='Inputs'\n",
    "        #                        ,facecolors='blue', marker='X')\n",
    "        for n in range (len(inputs)) :\n",
    "                predictions = conv_model(inputs[n:n+1])\n",
    "                predictions = predictions.numpy()\n",
    "                if n > 0 :\n",
    "                    predictions0 = conv_model(inputs[n-1:n])\n",
    "#                    ax2.scatter(inputs[n-1:n, :, 0], inputs[n-1:n, :, 1],label='Inputs'\n",
    "#                                ,facecolors='g', marker='*', s=64)\n",
    "                    predictions0 = predictions0.numpy()\n",
    "\n",
    "                    if predictions0[0,0,0] >  predictions[0,0,0] :\n",
    "                        predictions[0,0,0] = inputs[n+1,2,1]\n",
    "                        predictions[0,0,0] = inputs[n,-1:,1]\n",
    "                inputs[n+1,2,1] =predictions[0,0,0]\n",
    "                if n < len(inputs)-2 :\n",
    "                    inputs[n+2,1,1] =predictions[0,0,0]\n",
    "                else : break\n",
    "                if n < len(inputs)-3 :\n",
    "                    inputs[n+3,0,1] =predictions[0,0,0]\n",
    "                else :\n",
    "                    continue\n",
    "\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        inputs_res = inputs\n",
    "        predictions = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        predictions = conv_model(inputs)\n",
    "        ax2.scatter(lab[:,:, 0],  predictions[:, :, 0],marker='o', edgecolors=None, label='Predictions'\n",
    "             ,facecolors='red'  )# , c='#ff7f0e', s=64)\n",
    "        ax2.scatter(inputs[:, :, 0], inputs[:, :, 1],label='Inputs', marker='x')\n",
    "\n",
    "\n",
    "ax2.invert_xaxis()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## predict for any curve\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\n",
    "    os.path.join(mglearn.datasets.DATA_PATH, \"anycurve3.csv\") )\n",
    "#df2 = pd.read_csv(\n",
    "#    os.path.join(mglearn.datasets.DATA_PATH, \"constant(val).csv\") )\n",
    "# 예제를 위해 몇개의 열만 선택합니다\n",
    "#df = df[['IR', 'FlowHt', 'Const', 'Var', 'Base', 'MixS75','MixS50','MixS25']]\n",
    "#df = df[['IR', 'FlowHt', 'Sand','Ash','delIR','delFlow']]\n",
    "df3 = df3[['IR', 'FlowHt', 'Sand','Ash','delIR','delFlow']]\n",
    "#df2 = df2[['IR', 'FlowHt', 'Sand','Ash']]\n",
    "df3['delIF'] = df3['delFlow']/df3['delIR']*-1\n",
    "\n",
    "df3['delIF']=df3['delIF'].replace(np.nan, 0)\n",
    "df3 = df3[['IR', 'FlowHt', 'Sand','Ash' ]]\n",
    "\n",
    "display(df3.head())\n",
    "#display(df2.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df3_mean = df3.mean()\n",
    "df3_std = df3.std()\n",
    "df3_std_s = (df3 - df3_mean) / df3_std\n",
    "df3_std_m = df3_std_s.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df3_std_m)\n",
    "_ = ax.set_xticklabels(df3.keys(), rotation=90)\n",
    "df3_std_s.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df3_org = df3\n",
    "#df3 = df3_std_s\n",
    "\n",
    "#a =ttt_1.iloc[2]['tr']\n",
    "#b=a.append(ttt_1.iloc[2]['va'])\n",
    "#c = b.append(ttt_1.iloc[2]['te'])\n",
    "n = len(df3)\n",
    "c_0 = df3[0:int(n*0.25)].copy()\n",
    "c_1 = df3[int(n*0.25):int(n*0.5)].copy()\n",
    "c_2 = df3[int(n*0.5):int(n*0.75)].copy()\n",
    "c_3 = df3[int(n*0.75):int(n)].copy()\n",
    "\n",
    "\n",
    "wide_conv_window_t.train_df = c_0\n",
    "\n",
    "dataset = wide_conv_window_t.train\n",
    "fig, ax2 = plt.subplots()\n",
    "\n",
    "for i, batch in enumerate(dataset) :\n",
    "  inputs, targets, lab = batch\n",
    "  predictions = conv_model(inputs)\n",
    "  ax2.scatter(lab[:,:,0], predictions[:,:,0], marker='o', edgecolor ='b')\n",
    "#ax2.set_xlim([1.2, -2.5])\n",
    "\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "        curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-',\n",
    "        curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-',)\n",
    "\n",
    "ax2.plot(c_1.iloc[0:58,0], c_1.iloc[0:58,1], 'g--',\n",
    "        c_2.iloc[0:58,0], c_2.iloc[0:58,1], 'r--',\n",
    "        c_3.iloc[0:58,0], c_3.iloc[0:58,1], 'b--',\n",
    "        c_0.iloc[0:58,0], c_0.iloc[0:58,1], 'm--',)\n",
    "\n",
    "\n",
    "ax2.invert_xaxis()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize = (12,7))\n",
    "\n",
    "#------------------------------------------\n",
    "train_df_3 = curve_3.copy()\n",
    "#plots_t.plot_all(train_df_3, set_name='3 s25a75',   model=conv_model,window_t=conv_window_t,marker2='o' , edgecolor2 ='b')\n",
    "\n",
    "#------------------------------------------\n",
    "train_df_2 = curve_2.copy()\n",
    "#plots_t.plot_all(train_df_2, set_name='2 s50a50',   model=conv_model,window_t=conv_window_t,marker2='o' , edgecolor2 ='g')\n",
    "#------------------------------------------\n",
    "train_df_1 = curve_1.copy()\n",
    "#plots_t.plot_all(train_df_1, set_name='1 s75a25',  model=conv_model,window_t=conv_window_t, marker2='o' , edgecolor2 ='g')\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "train_df_0 = curve_0.copy()\n",
    "#plots_t.plot_all(train_df_0, set_name='0', marker2='o' ,model=conv_model,window_t=conv_window_t, edgecolor2 ='g')\n",
    "\n",
    "\n",
    "#------------------------------------------\n",
    "ax2.set_xlabel('norm IR')\n",
    "ax2.set_ylabel('Flow Height [m]')\n",
    "        #ax2.set_xlim([plt.xlim()[1], -2.5])\n",
    "#ax2.set_xlim([1., 0])\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "         curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-'\n",
    "          ,curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-')\n",
    "#------------------------------------------\n",
    "ax2.plot(c_1.iloc[0:58,0], c_1.iloc[0:58,1], 'g--',\n",
    "        c_2.iloc[0:58,0], c_2.iloc[0:58,1], 'r--',\n",
    "        c_3.iloc[0:58,0], c_3.iloc[0:58,1], 'b--',\n",
    "        c_0.iloc[0:58,0], c_0.iloc[0:58,1], 'm--',)\n",
    "\n",
    "\n",
    "def split_window( features ):\n",
    "    inputs = features[:, input_slice, :]\n",
    "    labels = features[:, labels_slice, :]\n",
    "    lab = features[:,  labels_slice, 0:2]\n",
    "\n",
    "    labels = tf.stack( [labels[:, :, 1] ])\n",
    "    print(f'in split_window : {inputs}')\n",
    "    print(f'in split_window : {labels}')\n",
    "\n",
    "    return inputs, labels, lab\n",
    "def makedata(data) :\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False, #default\n",
    "#      shuffle=True,\n",
    "      batch_size=60,)\n",
    "    ds = ds.map(split_window )\n",
    "    return ds\n",
    "\n",
    "input_width = 3\n",
    "label_width = 1\n",
    "shift = 1\n",
    "total_window_size = input_width + shift\n",
    "input_slice = slice(0, input_width)\n",
    "#input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "label_start = total_window_size - label_width\n",
    "labels_slice = slice(label_start, None)\n",
    "#label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "train_df_40 = c_0\n",
    "train_df_41 = c_1\n",
    "train_df_42 = c_2\n",
    "train_df_43 = c_3\n",
    "\n",
    "CONV_WIDTH = 3\n",
    "m1 = total_window_size-CONV_WIDTH\n",
    "m = CONV_WIDTH-1\n",
    "\n",
    "#data_set = [train_df_40, train_df_41, train_df_42, train_df_43  ]\n",
    "#data_set = [train_df_41, train_df_42, train_df_43  ]\n",
    "data_set = [train_df_40]\n",
    "\n",
    "for data in data_set :\n",
    "    #data = np.array(data, dtype=np.float32)\n",
    "    #data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
    "    conv_window_t.train_df = data\n",
    "    ds = conv_window_t.train\n",
    "#    wide_conv_window_t.train_df = data\n",
    "#    ds = wide_conv_window_t.train\n",
    "\n",
    "#    ds = makedata(data)\n",
    "\n",
    "    for i, batch in enumerate(ds) :\n",
    "        inputs, labels, lab = batch\n",
    "        inputs = inputs.numpy()\n",
    "\n",
    "        if i>0 :\n",
    "            for j in range (0, CONV_WIDTH-1) :\n",
    "                inputs[j, 0:CONV_WIDTH-j, 1] = inputs_res[-1:, j-CONV_WIDTH: , 1]\n",
    "\n",
    "\n",
    "        for n in range (len(inputs)-1) :\n",
    "\n",
    "                #if m1 == 1 and n == 0 :\n",
    "                if n == 0 :\n",
    "                    predictions = conv_model(inputs[n:n+1])\n",
    "                    predictions = predictions.numpy()\n",
    "                    inputs[n+1, m: , 1] = predictions[0, :, 0]\n",
    "                    inputs_res = inputs\n",
    "                else :\n",
    "                    inputs[n, 0:m, 1] = inputs_res[n-1, 1:m+1, 1]\n",
    "                    predictions = conv_model(inputs[n:n+1])\n",
    "                    predictions = predictions.numpy()\n",
    "                    inputs[n+1, m: , 1] = predictions[0,:,0]\n",
    "                    inputs_res = inputs\n",
    "\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        inputs_res = inputs\n",
    "\n",
    "        predictions = tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "        predictions = conv_model(inputs)\n",
    "        ax2.scatter(lab[:,:, 0],  predictions[:, :, 0],marker='o', edgecolors=None, label='Predictions'\n",
    "             ,facecolors='red'  )# , c='#ff7f0e', s=64)\n",
    "        ax2.scatter(inputs[:, :, 0], inputs[:, :, 1],label='Inputs', marker='x')\n",
    "\n",
    "\n",
    "ax2.invert_xaxis()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize = (12,7))\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "         curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-'\n",
    "          ,curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-')\n",
    "\n",
    "data_set = [train_df_40]\n",
    "\n",
    "for data in data_set :\n",
    "    conv_window_t.train_df = data\n",
    "    ds = conv_window_t.train\n",
    "\n",
    "#    ds = makedata(data)\n",
    "\n",
    "    for i, batch in enumerate(ds) :\n",
    "        inputs, labels, lab = batch\n",
    "        inputs = inputs.numpy()\n",
    "\n",
    "        if i>0 :\n",
    "            for j in range (0, CONV_WIDTH-1) :\n",
    "                inputs[j, 0:CONV_WIDTH-j, 1] = inputs_res[-1:, j-CONV_WIDTH: , 1]\n",
    "\n",
    "        for n in range (len(inputs)-1) :\n",
    "            if n > 0 : inputs = inputs_res\n",
    "            predictions = conv_model(inputs[n:n+1])\n",
    "            predictions = predictions.numpy()\n",
    "            inputs[n+1, CONV_WIDTH-1:, 1] = predictions[0, :, 0]\n",
    "            inputs_res = inputs\n",
    "\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        inputs_res = inputs\n",
    "\n",
    "        predictions = tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "        predictions = conv_model(inputs)\n",
    "        ax2.scatter(lab[:,:, 0],  predictions[:, :, 0],marker='o', edgecolors=None, label='Predictions'\n",
    "             ,facecolors='red'  )# , c='#ff7f0e', s=64)\n",
    "        ax2.scatter(inputs[:, :, 0], inputs[:, :, 1],label='Inputs', marker='x')\n",
    "\n",
    "\n",
    "ax2.invert_xaxis()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This may be the final!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize = (12,7))\n",
    "\n",
    "#------------------------------------------\n",
    "train_df_3 = curve_3.copy()\n",
    "#plots_t.plot_all(train_df_3, set_name='3 s25a75',   model=conv_model,window_t=conv_window_t,marker2='o' , edgecolor2 ='b')\n",
    "\n",
    "#------------------------------------------\n",
    "train_df_2 = curve_2.copy()\n",
    "#plots_t.plot_all(train_df_2, set_name='2 s50a50',   model=conv_model,window_t=conv_window_t,marker2='o' , edgecolor2 ='g')\n",
    "#------------------------------------------\n",
    "train_df_1 = curve_1.copy()\n",
    "#plots_t.plot_all(train_df_1, set_name='1 s75a25',  model=conv_model,window_t=conv_window_t, marker2='o' , edgecolor2 ='g')\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "train_df_0 = curve_0.copy()\n",
    "#plots_t.plot_all(train_df_0, set_name='0', marker2='o' ,model=conv_model,window_t=conv_window_t, edgecolor2 ='g')\n",
    "\n",
    "\n",
    "#------------------------------------------\n",
    "ax2.set_xlabel('norm IR')\n",
    "ax2.set_ylabel('Flow Height [m]')\n",
    "        #ax2.set_xlim([plt.xlim()[1], -2.5])\n",
    "#ax2.set_xlim([1., 0])\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "         curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-'\n",
    "          ,curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-')\n",
    "#------------------------------------------\n",
    "ax2.plot(c_1.iloc[0:58,0], c_1.iloc[0:58,1], 'g--',\n",
    "        c_2.iloc[0:58,0], c_2.iloc[0:58,1], 'r--',\n",
    "        c_3.iloc[0:58,0], c_3.iloc[0:58,1], 'b--',\n",
    "        c_0.iloc[0:58,0], c_0.iloc[0:58,1], 'm--',)\n",
    "\n",
    "\n",
    "def split_window( features ):\n",
    "    inputs = features[:, input_slice, :]\n",
    "    labels = features[:, labels_slice, :]\n",
    "    lab = features[:,  labels_slice, 0:2]\n",
    "\n",
    "    labels = tf.stack( [labels[:, :, 1] ])\n",
    "    print(f'in split_window : {inputs}')\n",
    "    print(f'in split_window : {labels}')\n",
    "\n",
    "    return inputs, labels, lab\n",
    "def makedata(data) :\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False, #default\n",
    "#      shuffle=True,\n",
    "      batch_size=60,)\n",
    "    ds = ds.map(split_window )\n",
    "    return ds\n",
    "\n",
    "input_width = 3\n",
    "label_width = 1\n",
    "shift = 1\n",
    "total_window_size = input_width + shift\n",
    "input_slice = slice(0, input_width)\n",
    "#input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "label_start = total_window_size - label_width\n",
    "labels_slice = slice(label_start, None)\n",
    "#label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "train_df_40 = c_0  #4060\n",
    "train_df_41 = c_1  #6040\n",
    "train_df_42 = c_2  #1090\n",
    "train_df_43 = c_3  #9010\n",
    "\n",
    "CONV_WIDTH = 3\n",
    "m1 = total_window_size-CONV_WIDTH\n",
    "m = CONV_WIDTH-1\n",
    "\n",
    "#data_set = [train_df_40, train_df_41, train_df_42, train_df_43  ]\n",
    "#data_set = [train_df_41, train_df_42, train_df_43  ]\n",
    "data_set = [train_df_43]\n",
    "\n",
    "for data in data_set :\n",
    "    #data = np.array(data, dtype=np.float32)\n",
    "    #data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
    "\n",
    "#    conv_window_t.train_df = data\n",
    "#    ds = conv_window_t.train\n",
    "    wide_conv_window_t.train_df = data\n",
    "    ds = wide_conv_window_t.train\n",
    "\n",
    "#    ds = makedata(data)\n",
    "\n",
    "    for i, batch in enumerate(ds) :\n",
    "        inputs, labels, lab = batch\n",
    "        inputs = inputs.numpy()\n",
    "\n",
    "        if i>0 :\n",
    "            #for j in range (0, CONV_WIDTH-1) :\n",
    "            #    inputs[j, 0:CONV_WIDTH-j, 1] = inputs_res[-1:, j-CONV_WIDTH: , 1]\n",
    "            inputs[0,:,1] = inputs_res[-1:,:,1]\n",
    "        for n in range (len(inputs)-1) :\n",
    "            if n > 0 : inputs = inputs_res\n",
    "            predictions = conv_model(inputs[n:n+1])\n",
    "            predictions = predictions.numpy()\n",
    "\n",
    "            inputs[n+1, 0:CONV_WIDTH-1, 1] = inputs[n, 1:CONV_WIDTH, 1]\n",
    "            inputs[n+1, CONV_WIDTH-1:, 1] = predictions[0, :, 0]\n",
    "            inputs_res = inputs\n",
    "\n",
    "\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        inputs_res = inputs\n",
    "\n",
    "        predictions = tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "        predictions = conv_model(inputs)\n",
    "#        ax2.scatter(lab[:,:, 0],  predictions[:, :, 0],marker='o', edgecolors=None, label='Predictions'\n",
    "#             ,facecolors='red'  )# , c='#ff7f0e', s=64)\n",
    "#        ax2.scatter(inputs[:, :, 0], inputs[:, :, 1],label='Inputs', marker='x')\n",
    "        ax2.scatter(lab[:,0, 0],  predictions[:, 0, 0],marker='o', edgecolors=None, label='Predictions'\n",
    "             ,facecolors='red'  )# , c='#ff7f0e', s=64)\n",
    "        ax2.scatter(inputs[:, 0, 0], inputs[:, 0, 1],label='Inputs', marker='x')\n",
    "\n",
    "\n",
    "\n",
    "ax2.invert_xaxis()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"wide_conv_window\")\n",
    "print('Input shape:', wide_conv_window.example[0].shape)\n",
    "print('Labels shape:', wide_conv_window.example[1].shape)\n",
    "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs.shape\n",
    "wide_conv_window_t\n",
    "conv_window_t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize = (12,7))\n",
    "\n",
    "#------------------------------------------\n",
    "ax2.set_xlabel('norm IR')\n",
    "ax2.set_ylabel('Flow Height [m]')\n",
    "\n",
    "ax2.plot(curve_1.iloc[0:58,0], curve_1.iloc[0:58,1], 'g-',\n",
    "        curve_2.iloc[0:58,0], curve_2.iloc[0:58,1], 'r-',\n",
    "         curve_3.iloc[0:58,0], curve_3.iloc[0:58,1], 'b-'\n",
    "          ,curve_0.iloc[0:58,0], curve_0.iloc[0:58,1], 'm-')\n",
    "#------------------------------------------\n",
    "ax2.plot(c_1.iloc[0:58,0], c_1.iloc[0:58,1], 'g--',\n",
    "        c_2.iloc[0:58,0], c_2.iloc[0:58,1], 'r--',\n",
    "        c_3.iloc[0:58,0], c_3.iloc[0:58,1], 'b--',\n",
    "        c_0.iloc[0:58,0], c_0.iloc[0:58,1], 'm--',)\n",
    "\n",
    "\n",
    "def split_window( features ):\n",
    "    inputs = features[:, input_slice, :]\n",
    "    labels = features[:, labels_slice, :]\n",
    "    lab = features[:,  labels_slice, 0:2]\n",
    "\n",
    "    labels = tf.stack( [labels[:, :, 1] ])\n",
    "    print(f'in split_window : {inputs}')\n",
    "    print(f'in split_window : {labels}')\n",
    "\n",
    "    return inputs, labels, lab\n",
    "def makedata(data) :\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False, #default\n",
    "#      shuffle=True,\n",
    "      batch_size=100,)\n",
    "    ds = ds.map(split_window )\n",
    "    return ds\n",
    "\n",
    "input_width = 3\n",
    "label_width = 1\n",
    "shift = 1\n",
    "total_window_size = input_width + shift\n",
    "input_slice = slice(0, input_width)\n",
    "#input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "label_start = total_window_size - label_width\n",
    "labels_slice = slice(label_start, None)\n",
    "#label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "train_df_40 = c_0\n",
    "train_df_41 = c_1\n",
    "train_df_42 = c_2\n",
    "train_df_43 = c_3\n",
    "\n",
    "\n",
    "data_set = [train_df_40, train_df_41, train_df_42, train_df_43  ]\n",
    "#data_set = [train_df_41, train_df_42, train_df_43  ]\n",
    "#data_set = [train_df_41]\n",
    "\n",
    "for data in data_set :\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
    "\n",
    "#    conv_window_t.train_df = data\n",
    "#    ds = conv_window_t.train\n",
    "\n",
    "    ds = makedata(data)\n",
    "\n",
    "    for i, batch in enumerate(ds) :\n",
    "        inputs, labels, lab = batch\n",
    "        inputs = inputs.numpy()\n",
    "        if i>0 :\n",
    "            inputs[0, 0:len(inputs)-1, 1] = inputs_res[-1:, -2: , 1]\n",
    "            inputs[0, -1:, 1] = inputs[0, -2:-1, 1]\n",
    "        #ax2.scatter(inputs[:, :, 0], inputs[:, :, 1],label='Inputs'\n",
    "        #                        ,facecolors='blue', marker='X')\n",
    "        for n in range (len(inputs)) :\n",
    "                predictions = conv_model(inputs[n:n+1])\n",
    "                predictions = predictions.numpy()\n",
    "                if n > 0 :\n",
    "                    predictions0 = conv_model(inputs[n-1:n])\n",
    "                    #ax2.scatter(inputs[n-1:n, :, 0], inputs[n-1:n, :, 1],label='Inputs'\n",
    "                    #            ,facecolors='g', marker='*', s=64)\n",
    "                    predictions0 = predictions0.numpy()\n",
    "\n",
    "                    if predictions0[0,0,0] >  predictions[0,0,0] :\n",
    "                        predictions[0,0,0] = inputs[n+1,2,1]\n",
    "                        predictions[0,0,0] = inputs[n,-1:,1]\n",
    "                inputs[n+1,2,1] =predictions[0,0,0]\n",
    "                if n < len(inputs)-2 :\n",
    "                    inputs[n+2,1,1] =predictions[0,0,0]\n",
    "                else : break\n",
    "                if n < len(inputs)-3 :\n",
    "                    inputs[n+3,0,1] =predictions[0,0,0]\n",
    "                else :\n",
    "                    continue\n",
    "\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        inputs_res = inputs\n",
    "\n",
    "        predictions = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        predictions = conv_model(inputs)\n",
    "        ax2.scatter(lab[:,:, 0],  predictions[:, :, 0], marker='x', edgecolors=None, label='Predictions'\n",
    "             ,facecolors='g'  )# , c='#ff7f0e', s=64)\n",
    "        #ax2.scatter(inputs[:, :, 0], inputs[:, :, 1],label='Inputs', marker='o')\n",
    "\n",
    "\n",
    "ax2.invert_xaxis()\n",
    "ax2.set_xlim([1., 0.8])\n",
    "ax2.set_ylim([0, 20])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "name": "venv_01",
   "language": "python",
   "display_name": "Python (venv_01)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}